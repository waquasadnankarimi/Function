{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRmnOGAUnr2vSJBg60GBma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/waquasadnankarimi/Function/blob/main/Supervised_Learning11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.\n",
        "\n",
        "Answer:\n",
        "- Simple Linear Regression (SLR) is a statistical and machine learning method used to model the relationship between one independent variable (X) and one dependent variable (Y) by fitting a straight line to the data.\n",
        "\n",
        "**The model is expressed as:**\n",
        "   - Y=a+bX\n",
        "\n",
        "**where:**\n",
        "- Y = dependent variable (the outcome we want to predict)\n",
        "- X = independent variable (the predictor)\n",
        "- a = intercept (value of Y when X = 0)\n",
        "- b = slope (how much Y changes for a one-unit change in X)\n",
        "\n",
        "**Purpose of Simple Linear Regression**\n",
        "\n",
        "- The primary purposes of SLR are:Â Prediction/Forecasting: To estimate the value of a continuous dependent variable based on a given value of an independent variable (e.g., predicting a student's score based on hours studied).\n",
        "- Modeling Relationships: To determine the strength and direction of the relationship between two variables, such as calculating how much of the variation in \\(Y\\) is explained by \\(X\\).\n",
        "- Understanding Impact: To quantify the direct influence of one variable on another, such as how much sales increase for every additional dollar spent on advertising.\n",
        "\n",
        "Question 2: What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "Answer:\n",
        "- The key assumptions of Simple Linear Regression, often remembered by the acronym LINE, are Linearity (a straight-line relationship between X and Y), Independence (errors are unrelated), Normality (errors are normally distributed), and Equal Variance (constant error variance, Homoscedasticity)\n",
        "\n",
        "**Here are the core assumptions in detail:**\n",
        "\n",
        "- Linearity: The relationship between the independent variable (X) and the dependent variable (Y) must be linear, meaning it can be represented by a straight line.\n",
        "- Independence of Errors: The errors (residuals) for each observation are independent of each other; one error doesn't predict another.\n",
        "- Normality of Errors: The residuals are normally distributed (follow a bell curve) for any given value of the independent variable.\n",
        "- Homoscedasticity (Constant Variance): The variance of the errors is constant across all levels of the independent variable.\n",
        "- Random Sampling: The data points are collected randomly from the population.\n",
        "\n",
        "Question 3: Write the mathematical equation for a simple linear regression model and explain each term.\n",
        "\n",
        "Answer:\n",
        "- **The mathematical equation for a Simple Linear Regression (SLR) model is:**\n",
        "  - Y=a+bX+Ïµ\n",
        "\n",
        "**where:**\n",
        "\n",
        "- Y = Dependent variable (the outcome we want to predict)\n",
        "- X = Independent variable (the predictor)\n",
        "- a = Intercept (value of Y when X = 0)\n",
        "- b = Slope coefficient (change in Y for a one-unit change in X)\n",
        "- Îµ (epsilon) = Error term (captures the variation in Y not explained by X)\n",
        "\n",
        "**Explanation:**\n",
        "- The equation describes a straight-line relationship between X and Y.\n",
        "- The slope (b) tells how strongly X influences Y.\n",
        "- The intercept (a) shows the baseline value of Y when X is zero.\n",
        "- The error term (Îµ) represents randomness, noise, or missing factors affecting Y\n",
        "\n",
        "Question 4: Provide a real-world example where simple linear regression can be\n",
        "applied.\n",
        "\n",
        "Answer:\n",
        "- A great real-world example for simple linear regression is a real estate company predicting house prices based on square footage, where square footage is the independent variable and price is the dependent variable, finding a straight-line relationship to estimate value for new listings.\n",
        "\n",
        "**Here's a breakdown of the house price example:**\n",
        "\n",
        "- Goal: Predict house sale price.\n",
        "- Independent Variable (X): Square footage of the house (what you control or know).\n",
        "- Dependent Variable (Y): Sale price of the house (what you want to predict).\n",
        "\n",
        "Question 5: What is the method of least squares in linear regression?\n",
        "\n",
        "Answer:\n",
        "- The method of least squares is a mathematical technique used in linear regression to find the best-fitting line through a set of data points by minimizing the sum of the squared errors (residuals).\n",
        "\n",
        "- Residuals are the differences between the actual values and the predicted values:\n",
        "  - Residual=(Yobservedâ€‹âˆ’Ypredictedâ€‹)\n",
        "- The method of least squares finds the line that minimizes:\n",
        "  - âˆ‘(Yobservedâ€‹âˆ’Ypredictedâ€‹)^2\n",
        "\n",
        "**Why square the errors?**\n",
        "\n",
        "- Squaring the errors ensures that:\n",
        "  - Positive and negative deviations donâ€™t cancel out\n",
        "  - Larger errors are penalized more heavily\n",
        "\n",
        "Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n",
        "\n",
        "Answer:\n",
        "- Logistic Regression is a statistical and machine learning algorithm used for classification problems. It predicts the probability that a given input belongs to a particular class, usually a binary outcome such as:\n",
        "  - Yes vs No\n",
        "  - Spam vs Not Spam\n",
        "  - Disease vs No Disease\n",
        "  - 0 vs 1\n",
        "\n",
        "- Instead of fitting a straight line, logistic regression uses the logistic (sigmoid) function to map predicted values into a probability between 0 and 1.\n",
        "\n",
        "**Logistic Regression Function:**\n",
        "\n",
        "P(Y=1âˆ£X)=1/1+e^âˆ’(a+bX)\n",
        "\n",
        "**How Logistic Regression differs from Linear Regression:**\n",
        "\n",
        "| Feature               | **Linear Regression**      | **Logistic Regression**          |\n",
        "| --------------------- | -------------------------- | -------------------------------- |\n",
        "| **Goal**              | Predict a continuous value | Predict a class (classification) |\n",
        "| **Output**            | Real numbers (âˆ’âˆž to +âˆž)    | Probability (0 to 1)             |\n",
        "| **Function used**     | Straight line              | Sigmoid (logistic) curve         |\n",
        "| **Type of problem**   | Regression                 | Classification                   |\n",
        "| **Error metric**      | MSE (Least Squares)        | Log Loss / Cross-Entropy         |\n",
        "| **Decision Boundary** | None                       | Yes (e.g., 0.5 threshold)        |\n",
        "\n",
        "Question 7: Name and briefly describe three common evaluation metrics for regression models.\n",
        "\n",
        "Answer:\n",
        "**Here are three common evaluation metrics for regression models:**\n",
        "- Â **Mean Absolute Error (MAE)**\n",
        "  - Description: MAE measures the average absolute difference between the actual observed values and the predicted values by the model. It provides a direct, interpretable measure of the average error in the same units as the target variable. It is robust to outliers because it treats all errors equally regardless of their magnitude.\n",
        "- **Mean Squared Error (MSE)**\n",
        "  - Description: MSE calculates the average of the squared differences between predicted and actual values. By squaring the errors, MSE heavily penalizes large errors, making it more sensitive to outliers than MAE. Because it is differentiable, it is commonly used as a loss function for optimization in machine learning algorithms.\n",
        "- **Root Mean Squared Error (RMSE)**\n",
        "  - Description: RMSE is the square root of the MSE. It is one of the most popular regression metrics because, like MAE, it returns the error metric to the same units as the target variable. However, because it is derived from squared errors, it still places a higher weight on large errors and is sensitive to outliers.\n",
        "\n",
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n",
        "\n",
        "Answer:\n",
        "- The purpose of the R-squared (RÂ²) metric in regression analysis is to measure how well the regression model explains the variance in the dependent variable (Y). It indicates the proportion of variation in Y that can be explained by the independent variable(s).\n",
        "\n",
        "**Interpretation:**\n",
        "- R2=1 â†’ Perfect fit (model explains 100% of the variation)\n",
        "- R2=0 â†’ Model explains none of the variation\n",
        "- Higher ð‘…^2 values indicate a better fit.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5s_w76dFP40-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qoydKP5P2rm",
        "outputId": "066e26a5-b235-4684-a52b-be14cb38db94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Question 9: Write Python code to fit a simple linear regression model using scikit-learn\n",
        "and print the slope and intercept.\n",
        "'''\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "Y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X, Y)\n",
        "\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: How do you interpret the coefficients in a simple linear regression model?\n",
        "\n",
        "Answer:\n",
        "- In a simple linear regression (\\(Y=a+bX\\)), the coefficients show how the dependent variable (\\(Y\\)) changes with the independent variable (\\(X\\)): the intercept (\\(a\\)) is the predicted \\(Y\\) when \\(X=0\\), while the slope (\\(b\\)) indicates that for a one-unit increase in \\(X\\), \\(Y\\) changes by \\(b\\) units, reflecting the direction (positive/negative) and strength of the relationship, holding all else constant.\n",
        "\n",
        "**Interpreting the Intercept (a)**\n",
        "- Definition: The value of the dependent variable (\\(Y\\)) when the independent variable X is zero.\n",
        "- Context Matters: Its practical meaning depends on whether X=0 is a realistic or meaningful scenario within your data (e.g., zero income vs. zero hours studied).\n",
        "\n",
        "Interpreting the Slope (b)\n",
        "- Direction:\n",
        "  - Positive (b>0): A direct relationship; as (X) increases, (Y) tends to increase.\n",
        "  - Negative (b<0): An inverse relationship; as (X) increases, (Y) tends to decrease.\n",
        "- Magnitude:\n",
        "  - The number itself tells you the amount of change in (Y) for each one-unit change in (X).\n",
        "  - Example: If (b=0.79) for R&D spend predicting profit, a $1 increase in R&D predicts a $0.79 increase in profit.\n",
        "- Units are Key: The magnitude's interpretation depends heavily on the units of (X) and (Y).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nGWufrS9b7r-"
      }
    }
  ]
}